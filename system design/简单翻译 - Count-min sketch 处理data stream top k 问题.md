# 目标
如何在**有限的空间和时间的约束下**解决人们感兴趣的流行问题，如**top-k查询**、heavy hitters 和频率范围查询。我们将看到，由于流模型的限制，通过**count-min sketch**，可以实现巨大的空间节约，而且不会损失大量的准确性。

** Count-min sketch**
Count-min sketch是由Cormode和Muthukrishnan在2005年设计的，count-min sketch用比哈希表或任何线性空间的键值字典更少的空间估计项目的频率。count-min Sketch和bloom filter 一样也是基于hash函数的，但是使用的场景不同。

# Count-min sketch 算法
##  插入
更新操作将一个 val 的另一个实例（或几个实例）添加到数据集中。使用 d 个哈希函数，更新在 at 上计算 d 个哈希值，对于每个哈希值 hj（at），1≤j≤d，在第j行的位置被增加ct（伪码显示如下：)
```python
CMS_UPDATE(at,ct):
	for j ← 1 to d 
    	CMS[j][hj(at)] = CMS[j][hj(at)] + ct
```
图4.2：在一个尺寸为3x8的初始空CMS上进行 x、y 和 z 的三次UPDATE操作。相应的，我们有3个哈希函数，对每个元素进行计算，得到的哈希值就是相应行的单元格号的索引。例如，h1(x)=3，所以在更新x的过程中，CMS[1]()[3]()的位置被递增了2。
![][image-1]
## 查询
就像更新一样，查询也是计算d个哈希值，它返回d个不同行中d个计数器中的最小值，其中第j行中的计数器位置由哈希值指定。

```python
# hj (at), 1 ≤ j ≤ d (pseudocode below)
CMS_ESTIMATE(at):
	min = INT_MAX
	for j ← 1 to d
	       if(CMS[j][hj(at)] < min)
	       min = CMS[j][hj(at)]
	return min
```

下图显示了一个估算工作的例子。我们可以看到，在不同元素的更新过程中，哈希值发生碰撞时，count-min sketch会高估一个元素的实际频率，但高估只发生在每一行都有碰撞的情况下。
图4.3: 对图4.2中的count-min草图进行估计操作的例子。在元素y的情况下，其真实频率是1，count-min sketch报告的正确答案是1（1、3和1的最小值）。然而，在元素x的情况下，其真实频率为2，count-min sketch报告为3（5，3和5的最小值）。参考图3.2来说服自己，在早期的更新操作中，y和z一起增加了所有被x使用的计数器，从而导致了对x的高估。
![][image-2]
关于误差概率的计算，我自己也没弄清楚，敢兴趣的可以继续深入了解。
这里只给出count-min Sketch 的宽度和深度对误差的影响：
count-min sketch 中的宽度似乎与误差带ε有关，而深度与失败概率δ有关，但这背后的关联是什么？主要的想法是，拉伸CMS的宽度会减少不同元素的哈希值在任何一行中的平均碰撞程度，但碰撞仍有可能发生很多。深度允许我们减少这种概率，因为要发生高估，我们要求每一行在相应的单元中都有高估。因此，举例来说，如果任何一行的某个单元格超出允许误差范围的几率最多为1/2，那么在有d行的情况下，一个元素被高估的几率最多为(1/2)^d，大大降低。
# 应用案例
## sensor smart-bed application
睡眠科学是最近的一件大事（可以说人们正在为他们的睡眠质量而失眠。）智能床的发明，配备了几十个能够记录不同参数的传感器，如运动、压力、温度等，为分析人们的睡眠模式和满足个别睡眠者的需求提供了新的机会。根据这些数据，床的组件可以被拉高（例如，帮助解决打鼾问题），升温，降温，等等。考虑到一家智能床公司在一个中央数据库收集数据，现在有数以百万计的用户，传感器每秒都会发出数据，数据量很快就变得太大，无法直接处理和分析。仅仅在一天的时间里，我们假设的公司总共收集了108（客户）∗3600（每小时的秒数）∗24（每天的小时数）∗100（传感器）=8.6∗1014个图元的数据，导致每天的存储量达到了TB级（具体例子是假设的，但收集的数据规模和我们研究的相关问题不是假设的）。
我们公司的SleepQuality应用程序的重点新功能之一是分析睡眠者的不稳定性，我们可以设想每个睡眠者被映射到睡眠质量尺度的某个地方。为了通知睡眠模式最不稳定的客户，该应用程序还保持了一个最不安分的睡眠者的顶级名单。

我们可以创建一个哈希表，为每个用户保存一个单独的条目，同时用一个整数来跟踪他们的睡眠质量数据，但这将导致一个巨大的哈希表，需要许多千兆字节。另外，如果我们希望通过分别存储来自同一张床的不同传感器的运动信息来进行更深入的分析，这将导致100亿个不同的（用户-ID，传感器）对。与其建立一个巨大的哈希表，我们将建立一个count-min sketch。

如图4.4所示，数据以频繁的速度从每个睡眠者那里到达，在每个时间步长，(user_id, amount) 对更新count-min sketch。给定用户的频率被更新为一个给定的数量。这样，count-min sketch在任何时候都可以为任何请求它的用户产生近似的估计。但是，为了维护前k名不眠者的名单，我们必须做得更多一些，而不仅仅是更新count-min sketch。请记住，count-min sketch并没有维护任何关于不同用户ID的信息，它只是一个计数器的矩阵。所以我们可以查询它，但我们需要知道用户的ID，或者我们必须把重要的用户存储在某个地方。
在进入解决方案之前，请思考什么是正确的数据结构，可以帮助以节省空间的方式存储前k个不稳定的睡眠者。

一种解决方案是使用结合count-min sketch 和最小堆。

## Approximate heavy hitters
heavy hitters 问题类似于top -k 问题，但是又不完全一样。HH(N,k)是heavy hitter问题的一个实例，在**频率总和为N**的数据流中（或者，**如果频率都是1**，那么N对应于数据流中迄今为止遇到的元素数量），我们感兴趣的是输出所有至少出现N/k次的项目。根据鸽子洞原则，最多可以有k个heavy hitters，所以只要我们有一个heavy hitter，我们也有一个处于top-k的元素，但另一个方向不成立：top-k元素不一定是heavy hitter。？？
### 多数元素
数组中占比超过一半的元素称之为多数元素。
leetcode 题目：[https://leetcode-cn.com/problems/majority-element/][3]
在继续前进之前，试着为多数人问题设计一个你能想到的最好的算法（从时间和空间的角度）。

这个问题可以用一种只用两个额外变量的 "一次通过阵列 "算法来解决。该算法的工作原理是在多数派元素的争夺战中存储当前的领先者，以及记录当前领先者领先多少的计数器。当我们从左到右扫过数组时，在数组的当前元素`A[i]`处，如果计数器为0（没有人领先），`A[i]`就成为领先者，计数器被设置为1。否则，如果计数器不是0（现有的领先者），那么计数器要么被递增---当`A[i]`等于领先者，要么被递减---当`A[i]`与领先者不同。因此，举例来说，在数组中：
```python
A = [4, 5, 5, 4, 6, 4, 4]
```
the sequence of (frontrunner, counter) pairs goes like this:
```python
(4,1),(4,0),(5,1),(5,0),(6,1),(6,0),(4,1)
```
最后的 `4 `确实是多数元素。
另一种更直观地思考这个问题的方法是，在数组中任意抓出一对互不相等的相邻数字，并把它们扔出去。然后收缩因扔掉这对数字而产生的洞，继续这个过程，直到没有更多的不同数字对可以扔掉（数组中只有一个不同的元素）。我们最终得到的元素---可能有多个出现---保证是多数。下面的例子显示了这个算法是如何工作的。
![][image-3]
这个算法的好处是，无论我们以何种顺序摆脱配对，它都能发挥作用，而且我们可以同时摆脱多个配对------这在MapReduce等并行化环境中可能很有用，我们可以将大数组分成多个子数组，让每个子数组单独执行这个算法，然后最后合并结果，在一个节点完成。

如果能将大多数元素的整洁解决方案扩展到一般的重击者问题上，那就更好了。现在的问题是，有许多潜在的重击者，因此有许多不同的计数器需要维护。在n=k/2的极端情况下，我们要找的是出现两次或两次以上的元素。

如果你考虑一个长的数据流，到目前为止我们发现的所有元素都是不同的，那么我们遇到的下一个项目可能是一个现有元素的重复，在这种情况下，我们有一个heavy hitter，或者一个新元素。这种设置在内存消耗方面确实让我们捉襟见肘，因为为了知道我们是有一个重复的还是一个新的元素，我们必须保持迄今为止遇到的所有元素。这个例子可以推广到其他的k值，它的存在应该让你相信，我们不可能总是以一次通过和亚线性空间来解决一般的heavy hitter问题，我们需要转向近似解决这个问题。
解决近似 heavy hitter 意味着我们将报告所有至少出现N/k-εN次的元素，也就是所有heavy hitter 加上所有离heavy hitter 最多只有εN的元素。我们可以通过构建一个ε=1/2k的count-min sketch来有效识别近似的heavy hitter。同样，就像在restless sleeper方案中一样，我们可以使用一个min-heap来保留最高得分者，当我们扫描数据流时，只将count-min sketch报告频率为N/k及以上的元素插入min-heap中。例如，当N=10^9，k=10^6时，min-heap将包含所有count-min sketch报告频率为1,000及以上的元素，而实际上这些元素的频率可能为500及以上。

原文中有更多的例子，想要了解更多的可以查看原文。
另外，针对top-k问题，还有一片设计相关的文章，可以查看：
[https://serhatgiydiren.github.io/system-design-interview-top-k-problem-heavy-hitters][4]

top k问题的思路就是：分治法 + hash + heap + k 路归并
空间优化：hash需要存储流中的所有元素，如果存入磁盘，io 太高，而且磁盘也有空间限制。优化的方法：使用count-min sketch 代替hash算法，这样实现巨大的空间节约。

原文：
[https://livebook.manning.com/book/algorithms-and-data-structures-for-massive-datasets/chapter-4/v-4/1][5]



[3]:	https://leetcode-cn.com/problems/majority-element/
[4]:	https://serhatgiydiren.github.io/system-design-interview-top-k-problem-heavy-hitters
[5]:	https://livebook.manning.com/book/algorithms-and-data-structures-for-massive-datasets/chapter-4/v-4/1

[image-1]:	https://tva1.sinaimg.cn/large/008i3skNly1gsbwhikjy3j30xr0u0420.jpg
[image-2]:	https://tva1.sinaimg.cn/large/008i3skNly1gsbx5x0xtnj30uc0u0dkl.jpg
[image-3]:	https://tva1.sinaimg.cn/large/008i3skNly1gsc0569laij30fq0frtc3.jpg