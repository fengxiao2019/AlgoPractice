# 4 How should causal relationships be tracked?
> All end-to-end tracing infrastructures must employ a mechanism to track the slices of intra-request and inter-request causality most relevant to their intended use cases. To avoid capturing superfluous relationships (e.g., portions of undesired slices or false causal relationships), tracing infrastructures “thread” metadata along with individual workflows and establish happens-before relationships only to items with the same (or related) metadata [9, 11, 19, 20, 37, 40, 43, 47, 48](). Section 4.1 describes different types of metadata and tradeoffs between them.
所有的端到端追踪基础设施必须采用一种机制来追踪与他们的预期用例最相关的`intra-request` 和 `inter-request` 的因果关系片断。为了避免捕获多余的关系（例如，不需要的部分片断或错误的因果关系），追踪基础设施将元数据与单个工作流程 "串联 "起来，并仅对**具有相同（或相关）元数据的项目**建立`happens-before`关系[9, 11, 19, 20, 37, 40, 43, 47, 48]()。第4.1节描述了不同类型的元数据和它们之间的权衡。
> In general, metadata can be propagated by storing it in thread-local variables when a single thread is performing causally-related work, and encoding logic to propagate metadata across boundaries (e.g., across threads, caches, or components) in commonly used libraries. We argue that systems should be designed with the ability to propagate reasonably generic metadata with their flow of execution and messages, as this is a key underlying primitive of all tracing infrastructures we describe.
一般来说，当单个线程执行因果关系的工作时，**元数据**可以通过存储在`thread-local`中来传播，并在常用的库中**埋点**来跨边界（例如跨线程、缓存或组件）传播元数据。我们认为，系统应该被设计成有能力将合理的通用元数据与他们的执行流和消息一起传播，因为这是我们描述的所有追踪基础设施的一个关键的基本要素。
> Though any of the approaches discussed below can preserve concurrency by establishing happens-before relationships, additional instrumentation is needed to capture forks and joins. Such structural trace points are discussed in Section 4.2. Of course, the causal-relationship model used by the tracing infrastructure must also be expressive enough to represent concurrency, forks, and joins.
尽管下面讨论的任何方法都可以通过建立`happen-before`的关系来保存并发性，但需要额外的工具来捕获`fork`和`join`。这样的结构性跟踪点将在第4.2节讨论。当然，追踪基础设施所使用的因果关系模型也必须有足够的表现力来表示并发性、`fork` 和`join`。

## 4.1 Tradeoffs between metadata types
4.1 元数据类型之间的权衡
> Per-workflow metadata can either be static or dynamic. Dynamic metadata can additionally be fixed-width or variable-width. There are three main issues to consider when determining which type of metadata to use. First is size. Larger metadata will result in larger messages (e.g., RPCs) or will constrain payload size. Second is brittleness (or resilience) to lost or unavailable data. Third is whether the approach enables immediate availability of full traces (or other data needed for analysis) without trace construction.
每个工作流的元数据可以是静态的，也可以是动态的。动态元数据还可以是固定宽度或可变宽度的。在决定使用哪种类型的元数据时，有三个主要问题需要考虑：首先是尺寸（size），较大的元数据会导致较大的消息（例如RPCs），或许会限制有效负载的大小。😡_第二是对丢失或不可用的数据的脆性（或复原力）_ 😡。第三是该方法是否能够在不建立跟踪的情况下立即提供完整的跟踪（或分析所需的其他数据）。
> Comparing the three approaches, fixed-width approaches limit metadata size compared to variable-width approaches. All fixed-width approaches are also brittle to data availability or loss, though in different ways and to differing degrees. Dynamic, variable-width approaches can be extremely resilient to data loss, but at the cost of metadata size. Additionally, dynamic, variable-width approaches are often necessary to avoid trace construction. Table 3 summarizes the tradeoffs between the various metadata-propagation approaches. The rest of this section describes them in more detail.
对比这三种方法，**固定宽度的方法**比**可变宽度的方法**限制了元数据的大小。所有的固定宽度方法对数据的可用性或丢失也很脆弱，尽管方式不同，程度也不同。动态的、可变宽度的方法可以对数据丢失有极大的弹性，但是以元数据大小为代价。此外，动态的、可变宽度的方法更适用于**避免追踪的构建？？**。表3总结了各种元数据传播方法之间的权衡。本节的其余部分将更详细地描述它们。
> **Static, fixed-width metadata**: With this approach, a single metadata value (e.g., a randomly chosen 64-bit workflow ID) is used to identify all causally-related activity. Tracing implementations that use this method must explicitly construct traces by joining trace-point records with the same metadata. When doing so, they must rely on clues stored with trace-point records to establish happens-before relationships. For example, to order causally-related activity within a single thread, they must rely on an external clock. Since network messages must always be sent by a client before being received by a server, tracing infrastructures that do not rely on synchronized clocks might establish happens-before relationships between client and server work using network send and receive trace points on both machines. To identify concurrent work within components, tracing implementations that use this approach might establish happens-before relationship via thread IDs. Pip [37](), Pinpoint [11](), and Quanto [18]() use static, fixed-width metadata.
**静态的、固定宽度的元数据**: 采用这种方法，一个单一的元数据值（例如，随机选择的64位工作流ID）被用来识别所有与因果相关的活动。使用这种方法的追踪实现必须通过连接具有相同元数据的追踪点记录来明确地构建追踪。在这样做的时候，他们必须依靠与跟踪点记录一起存储的线索来建立`happens-before`的关系。例如，为了在一个单一的线程中排列因果关系的活动，他们必须依靠外部时钟。由于网络信息在被服务器接收之前必须先由客户端发送，所以不依赖同步时钟的追踪基础设施可以使用两台机器上的网络发送和接收追踪点来建立客户端和服务器工作之间的发生前关系。为了识别组件内的并发工作，使用这种方法的追踪实现可以通过线程ID建立发生前的关系。Pip[37]()、Pinpoint[11]()和Quanto[18]()使用静态、固定宽度的元数据。
> This approach is brittle because it will be unable to properly order activity in cases where the external clues are lost (e.g., due to losing trace-point records) or are unavailable (e.g., because developers are not blessed with the ability to modify arbitrary sections of the distributed system’s codebase). For example, if thread IDs are lost or are not available, this approach might not be able to properly identify concurrent activity within a component.
这种方法是脆弱的，因为在外部线索丢失（例如，由于丢失跟踪点记录）或不可用（例如，由于开发人员没有能力修改分布式系统代码库的任意部分）的情况下，它将无法正确排序活动。例如，如果线程ID丢失或不可用，这种方法可能无法正确识别一个组件内的并发活动。

> **Dynamic, fixed-width metadata**: With this approach, simple logical clocks (i.e., single 64-bit values), in addition to a workflow ID, can be embedded within metadata, enabling tracing infrastructures to encode happens-before relationships without relying on external clues. To limit metadata size, a single logical times- tamp is used. Vector clocks are not feasible with fixed-width metadata because they would require metadata as wide as the number of threads in the entire distributed system. At each trace point, a new random logical-clock value is chosen and a happens-before relationship is created by storing both new and old logical-clock values in the corresponding trace record. Counters that are incremented at each trace point could also be used to implement logical clocks, but would be insufficient for ordering concurrent accesses. Both versions of X-Trace [19, 20]() use dynamic, fixed-width metadata. Dapper [43]() and both versions of Stardust [40, 47]() use a hybrid approach that combines the previous approach and this one. For example, Stardust [40, 47]() relies on an external clock to order activity within components and uses logical clocks to order inter-component accesses.
动态、固定宽度的元数据: 通过这种方法，除了工作流ID之外，简单的逻辑时钟（即单个64位值）可以嵌入到元数据中，使追踪基础设施能够在不依赖外部线索的情况下编码`happens-before` 关系。为了限制元数据的大小，使用了一个单一的逻辑时间戳。矢量时钟在固定宽度的元数据中是不可行的，因为它们需要的元数据宽度与整个分布式系统中的线程数一样大。在每个跟踪点，选择一个新的随机逻辑时钟值，并通过在相应的跟踪记录中存储新的和旧的逻辑时钟值来创建一个`happens-before`关系。在每个跟踪点上递增的计数器也可以用来实现逻辑时钟，但不足以对并发访问进行排序。X-Trace[19, 20]()的两个版本都使用动态的、固定宽度的元数据。Dapper[43]()和Stardust[40, 47]()的两个版本都使用了一种混合方法，结合了前一种方法和这种方法。例如，Stardust [40, 47]() 依靠外部时钟来安排组件内的活动，并使用逻辑时钟来安排组件间的访问。

> The dynamic, fixed-width approach is also brittle because it cannot easily order trace-point records when a subset of them are lost. For example, if a single trace-point record is lost, this approach will be unable to order the two trace fragments that surround it because both will have completely different logical-clock values for which no explicit happens-before relationship exists. Hybrid approaches, which do not change metadata values as often, are slightly less susceptible to this problem than approaches that always change metadata between trace points. Other approaches are also possible to reduce brittleness, but at the expense of space.
动态的、固定宽度的方法也是很脆的，因为当其中的一个子集丢失时，它不能轻易地对跟踪点记录进行排序。例如，如果一个跟踪点记录丢失了，这种方法将无法对围绕它的两个跟踪片段进行排序，因为这两个片段的逻辑时钟值完全不同，不存在明确的`happens-before`关系。混合方法，不经常改变元数据值，比起总是在追踪点之间改变元数据的方法，对这个问题的敏感度略低。其他方法也有可能减少脆性，但要以牺牲空间为代价。
![][image-1]
> Table 3: Tradeoffs between metadata types. Static and dynamic, fixed-width approaches are of constant size (e.g., a minimum of one or two 64-bit values), but are brittle and do not enable immediate use of trace data. Dynamic variable- width approaches can enable resiliency by incorporating [interval-tree ][17]clocks and can be used to obtain traces immediately, but the resulting metadata can be very large (e.g., its size could be proportional to the amount of intra-request concurrency and number of functions executed). Hybrid approaches represent a good inflection point because they are less brittle than pure static or dynamic approaches and are of constant size (e.g., a minimum of two 64-bit values).
表3：元数据类型之间的权衡。静态和动态的固定宽度的方法是恒定的大小（例如，最小的一个或两个64位的值），但是很脆弱，不能立即使用跟踪数据。动态变宽方法可以通过整合区间树时钟来实现弹性，并且可以用来立即获得跟踪数据，但是产生的元数据可能非常大（例如，其大小可能与请求内并发量和执行的函数数量成正比）。混合方法代表了一个很好的拐点，因为它们比纯粹的静态或动态方法更健壮（不脆弱），而且大小恒定（例如，最小为两个64位的值）。

**Dynamic, variable-width metadata**: With this approach, metadata assigned to causally-related activity can change in size in addition to value. Doing so would allow metadata to include interval-tree clocks [3]() instead of simple logical clocks. Like vector clocks, interval-tree clocks reduce brittleness since any two timestamps can be compared to determine if they are concurrent or if one happened before another. But, unlike vector clocks, interval-tree clocks can grow and shrink in proportion to the number of active threads. In contrast, variable-width vector clocks cannot shrink and so require width proportional to the maximum number of threads observed in a workflow. Vector clocks also require globally unique, well-known thread IDs [3](). Currently, no existing tracing infrastructure uses vector clocks or interval-tree clocks.
**动态的、可变宽度的元数据**：通过这种方法，分配给因果关系活动的元数据除了值（value）之外还可以改变大小。这样做将允许元数据包括**区间树时钟**[3]()而不是简单的逻辑时钟。像矢量时钟一样，区间树时钟减少了脆性，因为任何两个时间戳都可以被比较，以确定它们是否同时发生，或者一个发生在另一个之前。但是，与矢量时钟不同的是，区间树时钟可以根据活动线程的数量按比例增长和收缩。相反，可变宽度的矢量时钟不能收缩，因此需要与工作流中观察到的最大线程数成比例的宽度。矢量时钟还需要全球唯一的、众所周知的线程ID[3]()。目前，没有任何现有的追踪基础设施使用矢量时钟或间隔树时钟。

> Tracing infrastructures that wish to make full traces (or other data that requires tying together causally- related activity) available immediately without explicit trace construction must use dynamic, variable-width metadata. For example, tracing infrastructures that use dynamic, variable-width metadata could carry executed trace-point records within metadata, making them immediately available for use as soon as the workflow ends. Whodunit [9]() is the only existing tracing implementation that carries trace-point records (i.e., function names) in metadata. To reduce metadata size, heuristics are used to reduce the number of propagated trace-point records, but trace fidelity is reduced as a result.
希望在没有明确的跟踪构建的情况下立即提供完整的跟踪（或其他需要将因果关系的活动联系起来的数据）的跟踪基础设施必须使用动态的、可变宽度的元数据。例如，使用动态、可变宽度元数据的追踪基础设施可以在元数据中携带已执行的追踪点记录，一旦工作流程结束，就可以立即使用这些记录。Whodunit[9]()是唯一一个在元数据中携带跟踪点记录（即函数名称）的现有跟踪实现。为了减少元数据的大小，**启发式方法**被用来减少传播的追踪点记录的数量，但追踪的保真度也因此而降低。
## 4.2 How to preserve forks and joins
4.2 如何保存fork和join
> For the static and dynamic, fixed-width metadata-propagation approaches discussed above, forks and joins can be preserved via one-to-many and many-to-one trace points. For the static approach, such trace points must include clues that uniquely identify the activity being forked or waited on—for example, thread IDs. For dynamic, fixed-width approaches, one-to-many trace points should include the current logical-clock value and the logical-clock values that will be initially used by each of the forked descendants. Join trace points should include the current logical-clock value and the logical-clock values of all events that must complete before work can proceed. Dynamic, variable-width approaches can infer forks and joins if they include interval-tree clocks.
对于上面讨论的静态和动态、固定宽度的元数据传播方法，fork 和 join 可以通过**一对多**和**多对一的跟踪点**来保存。对于**静态方法，这种跟踪点必须包括唯一识别被fork 或等待的活动的线索--例如，线程ID**。对于**动态的、固定宽度的方法，一对多****的跟踪点应该包括当前的逻辑时钟值和每个fork 的子孙最初使用的逻辑时钟值**。连接跟踪点应该包括当前的逻辑时钟值和所有在工作进行之前必须完成的事件的逻辑时钟值。动态的、可变宽度的方法可以推断出分叉和连接，如果它们包括区间树时钟的话。
> An alternate approach, used by Mann et al. [31](), involves comparing large volumes of traces to automati- cally determine fork and join points.

Mann等人[31]()使用的另一种方法是通过比较大量的跟踪来自动确定 fork 和join 的点。

[17]:	https://en.wikipedia.org/wiki/Interval_tree


[image-1]:	https://tva1.sinaimg.cn/large/008i3skNly1gsvlo5c2hmj310809y75a.jpg