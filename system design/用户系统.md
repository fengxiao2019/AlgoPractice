# 用户系统

## 功能需求
一个用户系统至少应该具备登陆、注册、查询、修改信息等功能。
## 非功能需求
假设我们设计的系统需要支撑以下指标（以twitter为例）：
DAU：1亿
QPS：10K
延迟：P99 1s
存储估计：假设用户规模为2亿用户
内存估计：
流量估计：

## 服务划分
假设每个季度新增1400万用户，用户注册接口的QPS为：
```python
1400 * 1000 / (30 * 3)/ (3600 * 24) = 1.8
```
假设每天有百分之1的用户会修改用户信息
```python
10000 * 100 / (3600 * 24) = 12
```
假设每天有百分之1的用户会重新登陆
```python
10000 * 100 / (3600 * 24) = 12
```
用户查询，假设平均每天每个用户查询100次
```python
10000 * 10000 * 100 / (3600 * 24) = 100k
```

每台MySQL单机能够承受的QPS大概为1K，所以，通过上面的分析，我们大概知道此次设计的系统大概需要400～600台。
根据经验值，qps为100k，至少需要上百台web服务。
从功能划分以及高低频接口可以将系统划分为以下几个服务：
用户的查询属于高频接口，用户信息的修改、用户的查询接触的数据更接近，把这两个功能放到一个service里面。
-  用户的注册和登录
- 用户的查询和用户信息的修改
- 用户关系查询
### 用户注册和登录服务
#### 注册和登录服务有如下特征：
- QPS比较低，峰值也就几百QPS
	- 用户信息属于结构化信息，可以使用MySQL存储
	- DAU为1亿用户，注册用户可以估计为2亿，假设一条用户信息为1k，数据规模为200G，一般来讲单表规模超过2G或者表的行数大于500万行时，需要对大表进行拆分，当然这并不是绝对的，需要结合实际情况，确认是否影响到业务。
#### DB Schema 设计
**用户信息表 User **
```python
table auth
id	bigint
user_id		bigint
password	varchar(128)
username	varchar(150)
```
**Session**
```python
session_key	varchar(40)
session_data	longtext
expire_date		datetime(6)
```

#### 1.  注册功能的实现
```python
register(username: str, phone: phone, **kwargs)->None:
	pass
```
#### 登陆和保持登录功能的实现
```python
def login(username:str, password: str) -> bool:
	pass
```
在后端保持用户登陆功能的方式是通过session 实现。
1. client 发起登陆请求（post method with username and password） —\> server
2. server 根据验证username 和 password
	>  2.1 验证失败，返回403
	> 2.2 验证通过，创建一条session记录存储到session 表中
	> 2.3 server 将session_key放到http response 的header 对应的Cookie字段中。
	> ```python
	> # https://stackoverflow.com/questions/817882/unique-session-id-in-python/6092448#6092448
	> session_id="49dc5033b62bca3d59e31204a28ce45e"
	> # 生成方式
	> import uuid, M2Crypto
	> uuid.UUID(bytes = M2Crypto.m2.rand_bytes(num_bytes)).hex
	> ```

3. client下次发送请求时会自动带上Cookie信息
4. sever 检测request中Cookie信息中的session_id是否有效，如果有效就认为登陆成功。
#### 用户登出功能
用户登出时，需要将session信息从数据库中删除。
```python
def logout(username: str):
	pass
```
### 2. 获取用户信息功能
用户详细信息包含：用户名、手机号、邮件、头像等数据
用户详细信息存储在哪？（问题：是选择SQL数据库还是NoSQL数据库？）
用户详情信息的操作主要是查询和更新，查新和更新的比例大概能够到达1000:1甚至更高。基于SQL和NoSQL数据库选择的标准，存储用户信息既可以选择SQL数据库，也可以选择NoSQL数据库。
#### 选择SQL数据库存储
特征：用SQL DB存储，Schema固定，添加字段影响范围比较大，数据以行为单位。大规模数据集合下，需要手动分区和维护。
B: online DDL更新热点表的影响？
一条数据以行为单位
schema
```python
table user_profile
# 字段
email varchar(40)
phone varchar(30)
avator varchar(64)
username varchar(150)
...
...
```
#### 选择NoSQL存储
特征：Column 是动态的，可以随时添加
存储方式，以mongodb为例
```python
user_id
{
	'username': '',
	'email': '',
	'avator': '',
	'phone': ''，
	'xxx': ''
}
```
在数据规模比较大时，会自动进行分区。
### 3. 好友关系功能
功能：获取用户的好友关系（假设是单向好友关系）A 关注了B，那么B是A的好友
from_user是A
end_user 是B
#### API
```python
获取用户好友关系
def getFriendShip(user_id: int) -> List[int]:
	pass
```
#### - 存储
```python
表名 friendship
id 		   bigint
from_user  bigint
to_user	   bigint

# 查询user_id为1343的好友
# select to_user from friendship where from_user = 1343;

```

### Scale
#### session 数据是存储在数据库还是缓存中？
除了注册和登录本身不需要session的验证之外，其它API的请求都会用到session的验证，所以如果session存储在DB中，session表的查询QPS为100k级别。
而且，考虑到session的特性，一般server会设置一个很长的过期时间，也就是说session表本身具备写多读少的特征，这种情况下，我们可以采用cache对session的查询进行优化。
只用cache 做session存储：
优点：不用考虑缓存一致性的问题。
缺点：当缓存服务器宕机时，系统无法提供服务，相比于cache+db的存储方式，可用性较低。
cache + DB做session存储：
优点：可用性更高。
缺点：更复杂，需要考虑缓存一致性的问题，考虑缓存雪崩的问题。
#### 如何保证缓存一致性？
DB和cache 分属两个组件，需要业务端保证数据的一致性。
场景1: 缓存中session_id存在，并且有效
这种场景比较简单，直接获取cache数据验证就可以
场景2: 缓存中session_id不存在
step1: 从DB中获取session信息
step2: 检查是否过期
step2.1 过期：服务端返回403
step2.2 没过期 且 有效：服务端回写cache，返回查询结果
step2.3 没过期 且 无效：服务端返回403
场景3: 缓存中存在session_id，但是无效
step1: del cache，返回403

#### 缓存驱逐策略？
缓存的驱逐策略有两种：LRU和LFU。

#### 如何避免缓存雪崩问题？
![][image-1]
可能引起缓存雪崩的原因：
- 场景1: 用户session_id 设置的过期时间过于集中，导致大批用户在同一时间集中过期，缓存失效，请求全部落到**注册登录服务**的DB上，导致其DB不可用（注册登录服务的DBqps较低，整体配置满足不了高1000倍的QPS）。
- 场景2: 缓存服务器宕机。
针对场景1的策略：分散设置缓存过期时间，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
针对场景2的策略：
1. 提高缓存服务器的可用性。
2. DB访问限流，提供有损服务。
#### 目前用户信息都是存储在数据库中，用户信息查询的QPS为100k，如何保证P95为1s？
用户信息的的读写频率大于1000，属于读多写少的特征，可以使用cache进行优化，将50%的用户数据写入到cache中，使用LRU淘汰策略进行数据淘汰。
常见的缓存服务器有两个：Redis 和 Memcached，延迟时间都在亚毫秒级别，能够满足P95为1s的性能要求。

#### 如何避免单点？
通常我们采用冗余的方式来避免单点，提高系统的可靠性和可用性（串联系统的可靠性更低）。
三个服务的数据量都比较大，为了提高系统的可用性，需要对数据进行分库分表。
- 用户注册和登录服务
	-特征：qps低（100左右）数据规模大（20G），SQL DB存储。
	-分库分表方式：
	- 采用分表的方式，按照user_id范围划分，单表1千万个用户，划分成10个表。
		- 数据库采用1主一从的配置方式，同时采用半同步（冷备）的方式提高系统可用性。 
			![][image-2]
- 用户查询和用户信息修改功能
	- 特征：QPS高（300k），数据规模大（20G），采用NoSQL存储。例如，MongoDB至关重要的特色之一就是其内置的分片功能。这一功能允许多个普通的商用服务器之间分担数据量以及数据库负载。
	- [选择分片键，分片键的选择要满足以下功能][1]。
		- 所有的插入、更新以及删除将会均匀分发到集群中的所有分片中。
		- 所有的查询将会在集群中的所有分片中平均地分发。
		- 所有的操作将会只面向相关的分片：更新或者删除操作将不会发送到一个没有存储被修改数据的分片上。
		- 相似地，一个查询将不会被送到没有存储被查询数据的分片上。
			基于上述选择分片键的原则，以及业务访问场景，选择user_id 作为分片键，分片的方式有两种，一种是hash分片的方式，一种是按范围分片。
			- 按照范围分片，有可能会导致访问倾斜和数据倾斜，因此，这里我们采用hash分区的方式。
- 好友关系查询服务
	- 特征：QPS高（300k），数据规模大（20G），数据库采用SQL DB存储的方式。
		很明显，这个服务QPS高，数据规模大，需要采用分库的方式。单个MySQL的QPS为1k，那么需要的MySQL集群的数量超过400台，单机存储规模500M。为了避免数据倾斜和数据访问倾斜，我们采用hash分区的方式。
		普通的hash分区方式（直接取模hash）在节点故障或者增加节点时迁移大量的数据。为了避免这种问题，我们可以采用一致性hash算法。
---- -

在做系统设计时，都会涉及到非功能相关的需求考量，例如吞吐量、延迟等。
在批处理系统中，通常关心的吞吐量(throughput)，即每秒可处理的记录的条数，或者在指定的数据集上运行作业所需的总时间。
在线系统通常关心的响应时间，即客户端从发送请求到接收响应之间的间隔。
延迟（latency）：请求花费在处理上的时间。
响应时间（response time）：处理请求的时间 + 来回的网络延迟 + 排队延迟。

如果表达延迟 和 响应时间？
避免使用平均值，因为平均值无法告诉有多少用户实际经历了多少延迟。
推荐采用百分位数。
中位数-p50: eg. p50=200ms ，表示有一半的请求响应不到200ms，另一半请求则需要更长的时间。非常适合描述多少用户需要等待多长时间。
更高的百分位数 p95 、p99 ：分别表示有95%、99%的响应时间超过阈值。eg：p95=1.5s，表示95个请求响应时间在1.5s内，5个请求响应时间超过1.5s。
如何监控百分位数？
设置一个10分钟的滑动窗口，监控其中的响应时间，滚动计算窗口中的中位数和各种百分位数，然后绘制性能图标。

阿里巴巴《Java 开发手册》提出单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表
针对特定负载设计的架构不太可能应付预设目标10倍的实际负载。


[1]:	https://mongoing.com/blog/post/on-selecting-a-shard-key-for-mongodb

[image-1]:	https://tva1.sinaimg.cn/large/008i3skNly1gqnw7qqb3uj30sc0uedi8.jpg
[image-2]:	https://tva1.sinaimg.cn/large/008i3skNly1gqnwmjqmljj30v60f6js4.jpg